{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TwoLayerNet in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rusta\\anaconda3\\envs\\ece5831-2023\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define a simple model using Keras' Sequential API\n",
    "model = models.Sequential([\n",
    "    layers.Dense(100, activation=\"sigmoid\", input_shape=(784, )),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need training data!!\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape 28x28 to 784\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize values to 0 .. 1\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test =  to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5263 - loss: 1.8555\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8356 - loss: 0.8012\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8646 - loss: 0.5672\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8814 - loss: 0.4722\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8907 - loss: 0.4186\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8963 - loss: 0.3889\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8972 - loss: 0.3727\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.3546\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.3411\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9062 - loss: 0.3284\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9090 - loss: 0.3196\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.3111\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.3085\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9156 - loss: 0.2957\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2929\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2905\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9189 - loss: 0.2832\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2823\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9218 - loss: 0.2715\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9217 - loss: 0.2717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20cf8f15150>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 6, 9], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(y_test[0:10], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions == labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    def __init__(self, batch_size=32, epochs=20):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "        self._create_lenet()\n",
    "        self._compile()\n",
    "    \n",
    "\n",
    "    def _create_lenet(self):\n",
    "        self.model = Sequential([\n",
    "            Conv2D(filters=6, kernel_size=(5,5), \n",
    "                   activation='sigmoid', input_shape=(28, 28, 1), \n",
    "                   padding='same'),\n",
    "            AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "            \n",
    "            Conv2D(filters=16, kernel_size=(5,5), \n",
    "                   activation='sigmoid', \n",
    "                   padding='same'),\n",
    "            AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Dense(120, activation='sigmoid'),\n",
    "            Dense(84, activation='sigmoid'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    def _compile(self):\n",
    "        if self.model is None:\n",
    "            print('Error: Create a model first..')\n",
    "        \n",
    "        self.model.compile(optimizer='Adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "    def _preprocess(self):\n",
    "        # load mnist data\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        # normalize\n",
    "        x_train = x_train/255.0\n",
    "        x_test = x_test/255.0\n",
    "\n",
    "        # add channel dim\n",
    "        self.x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)  \n",
    "        self.x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)  \n",
    "\n",
    "        # one-hot encoding\n",
    "        self.y_train = to_categorical(y_train, 10)\n",
    "        self.y_test = to_categorical(y_test, 10)\n",
    "\n",
    "    def train(self):\n",
    "        self._preprocess()\n",
    "        self.model.fit(self.x_train, self.y_train, \n",
    "                  batch_size=self.batch_size, \n",
    "                  epochs=self.epochs)\n",
    "    \n",
    "    def save(self, model_path_name):\n",
    "        self.model.save(f\"{model_path_name}.keras\")\n",
    "        print(\"Successfully saved model\")\n",
    "\n",
    "    def load(self, model_path_name):\n",
    "        self.model = load_model(f\"{model_path_name}.keras\")\n",
    "        print(\"Successfully loaded model\")\n",
    "    \n",
    "    def predict(self, images):\n",
    "        x_test_subset = images.reshape(-1, 28, 28, 1)\n",
    "        predictions = np.argmax(self.model.predict(x_test_subset), axis=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rusta\\anaconda3\\envs\\ece5831-2023\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet(batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3879 - loss: 1.7174\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9188 - loss: 0.2749\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9493 - loss: 0.1673\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9625 - loss: 0.1243\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9656 - loss: 0.1077\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9732 - loss: 0.0878\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9768 - loss: 0.0758\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9788 - loss: 0.0688\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9813 - loss: 0.0607\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9824 - loss: 0.0539\n"
     ]
    }
   ],
   "source": [
    "lenet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Predictions: [7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "#predictions = np.argmax(lenet.model.predict(x_test[0:10]), axis=1)\n",
    "\n",
    "# Ensure the input is reshaped to the correct shape: (10, 28, 28, 1)\n",
    "x_test_subset = lenet.x_test[0:10].reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Get predictions for the first 10 test samples\n",
    "predictions = np.argmax(lenet.model.predict(x_test_subset), axis=1)\n",
    "\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(lenet.y_test[0:10], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(predictions == labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model\n"
     ]
    }
   ],
   "source": [
    "lenet.save(\"Aslam_cnn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new instance, and loading the previously saved model into the new instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lenet = LeNet()\n",
    "\n",
    "new_lenet.load(\"Aslam_cnn_model\")\n",
    "\n",
    "x_test_subset = lenet.x_test[0:10].reshape(-1, 28, 28, 1)\n",
    "predictions = np.argmax(new_lenet.model.predict(x_test_subset), axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure predict function works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = new_lenet.predict(lenet.x_test[0:10])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Handwriting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open(\"5_2.png\")\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_filename = \"5_4.png\"\n",
    "new_image = Image.open(image_filename).convert('L') \n",
    "new_image = new_image.resize((28,28)) \n",
    "new_image = np.array(new_image)\n",
    "new_image = 255 - new_image\n",
    "new_image = (new_image - np.min(new_image)) * (255 / (np.max(new_image) - np.min(new_image)))\n",
    "new_image = new_image.astype(np.float32) / 255.0  \n",
    "new_image = new_image.flatten()\n",
    "new_image = new_image.reshape((1, 784))\n",
    "\n",
    "res = new_lenet.predict(new_image)\n",
    "res "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece5831-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
